---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---


See also my [Google Scholar](https://scholar.google.com/citations?user=9dSlc_cAAAAJ&hl=en) and [Semantic Scholar](https://www.semanticscholar.org/author/Mufan-Bill-Li/49140558) pages. 

[**Sampling from the Mean-Field Stationary Distribution**](https://arxiv.org/abs/2402.07355) \\
Yunbum Kook, Matthew S. Zhang, Sinho Chewi, Murat A. Erdogdu, and **M. Li**. \\
To appear at *COLT 2024*. 
\[[arXiv](https://arxiv.org/abs/2402.07355)\]

[**Differential Equation Scaling Limits of Shaped and Unshaped Neural Networks**](https://arxiv.org/abs/2310.12079) \\
**M. Li** and Mihai Nica. \\
*TMLR* 2024. 
\[[arXiv](https://arxiv.org/abs/2310.12079)\]
\[[OpenReview](https://openreview.net/forum?id=iRDwUXYsSJ)\]

[**Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit**](https://arxiv.org/abs/2309.16620) \\
Blake Bordelon, Lorenzo Noci, **M. Li**, Boris Hanin, and Cengiz Pehlevan. \\
*ICLR* 2024. 
\[[arXiv](https://arxiv.org/abs/2309.16620)\]
\[[OpenReview](https://openreview.net/forum?id=KZJehvRKGD)\]


[**The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit**](https://arxiv.org/abs/2306.17759) \\
Lorenzo Noci\*, Chuning Li\*, **M. Li**\*, Bobby He, Thomas Hofmann, Chris Maddison, and Daniel M. Roy. \\
*NeurIPS* 2023. 
\[[arXiv](https://arxiv.org/abs/2306.17759)\] 
\[[Proceeding](https://papers.nips.cc/paper_files/paper/2023/hash/aa31dc84098add7dd2ffdd20646f2043-Abstract-Conference.html)\]

[**Improved Discretization Analysis for Underdamped Langevin Monte Carlo**](https://arxiv.org/abs/2302.08049) \\
Matthew Zhang, Sinho Chewi, **M. Li**, Krishnakumar Balasubramanian, and Murat A. Erdogdu. \\
*COLT* 2023. 
\[[arXiv](https://arxiv.org/abs/2302.08049)\]
\[[Proceeding](https://proceedings.mlr.press/v195/zhang23a.html)\]

[**Riemannian Langevin Algorithm for Solving Semidefinite Programs**](https://arxiv.org/abs/2010.11176)\\
**M. Li** and Murat A. Erdogdu.
\\
<!--  -->
*Bernoulli* 2023. 
\[[arXiv](https://arxiv.org/abs/2010.11176)\] 
\[[Journal](http://dx.doi.org/10.3150/22-BEJ1576)\] \\
Student Research Presentation Award at SSC 2021. 

[**The Neural Covariance SDE: Shaped Infinite-Depth-and-Width Networks at Initialization**](https://arxiv.org/abs/2206.02768) \\
**M. Li**, Mihai Nica, and Daniel M. Roy. \\
*NeurIPS* 2022, **Oral**. 
\[[arXiv](https://arxiv.org/abs/2206.02768)\] 
\[[Proceeding](https://papers.nips.cc/paper_files/paper/2022/hash/45fc4a0da7e7f6fbabaabe2d20a441d1-Abstract-Conference.html)\] 
\[[Code](https://openreview.net/attachment?id=WG3vmsteqR_&name=supplementary_material)\] 
\[[DL Foundations at UMD (Video)](https://youtu.be/LQw6XAJLL5s)\] 
\[[OPTML++ at MIT (Video)](https://youtu.be/au_i6pgcJBU)\]

[**Acceleration of Gossip Algorithms through the Euler-Poisson-Darboux Equation**](https://arxiv.org/abs/2202.10742) \\
Rapha&euml;l Berthier and **M. Li** (alphabetical). \\
*IMA Journal of Applied Mathematics* 2022. 
\[[arXiv](https://arxiv.org/abs/2202.10742)\]
\[[Journal](https://academic.oup.com/imamat/advance-article/doi/10.1093/imamat/hxac029/6775269)\]

[**Analysis of Langevin Monte Carlo from Poincar&eacute; to Log-Sobolev**](https://arxiv.org/abs/2112.12662) \\
Sinho Chewi, Murat A. Erdogdu, **M. Li**, Ruoqi Shen, and Matthew Zhang (alphabetical). \\
*COLT* 2022 Extended Abstract. 
\[[arXiv](https://arxiv.org/abs/2112.12662)\]
\[[Proceeding](https://proceedings.mlr.press/v178/chewi22a.html)\]

[**The Future is Log-Gaussian: ResNets and Their Infinite-Depth-and-Width Limit at Initialization**](https://arxiv.org/abs/2106.04013) \\
**M. Li**, Mihai Nica, and Daniel M. Roy. \\
*NeurIPS* 2021. 
\[[arXiv](https://arxiv.org/abs/2106.04013)\] 
\[[Proceeding](https://proceedings.neurips.cc/paper/2021/hash/412758d043dd247bddea07c7ec558c31-Abstract.html)\] 
\[[Code](https://openreview.net/attachment?id=-h99IwQN-f&name=supplementary_material)\] 


[**Higher Order Generalization Error for First Order Discretization of Langevin Diffusion**]() \\
**M. Li** and Maxime Gazeau. \\
*Preprint* 2021. 
\[[arXiv](https://arxiv.org/abs/2102.06229)\] 


\* Equal Contribution. 

















